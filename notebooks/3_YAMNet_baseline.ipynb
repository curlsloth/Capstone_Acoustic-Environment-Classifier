{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e748249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-20 23:11:05.184305: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-20 23:11:09.231906: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f92587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan data directories\n",
    "import glob\n",
    "\n",
    "nature_file_list = []\n",
    "nature_file_list += glob.glob('../data/interim/AmbisonicSoundLibrary/nature/*')\n",
    "nature_file_list += glob.glob('../data/interim/GoogleAudioSet/Outside, rural or natural/*')\n",
    "nature_file_list += glob.glob('../data/interim/youtube/NatureSoundscapes/*')\n",
    "nature_file_list += glob.glob('../data/interim/youtube/NomadicAmbience_nature/*')\n",
    "nature_file_list += glob.glob('../data/interim/S2L_LULC/non_urban/*')\n",
    "nature_file_list += glob.glob('../data/interim/S2L_LULC/urban_0_25/*')\n",
    "\n",
    "city_file_list = []\n",
    "city_file_list += glob.glob('../data/interim/GoogleAudioSet/Outside, urban or manmade/*')\n",
    "city_file_list += glob.glob('../data/interim/youtube/NomadicAmbience_city/*')\n",
    "city_file_list += glob.glob('../data/interim/SONYC/**/*.pkl')\n",
    "city_file_list += glob.glob('../data/interim/S2L_LULC/urban_26_100/*')\n",
    "\n",
    "nature_source_list = ['nature_'+i.rsplit('/', 3)[1]+'/'+i.rsplit('/', 3)[2] for i in nature_file_list]\n",
    "city_source_list = ['city_'+i.rsplit('/', -1)[3] for i in city_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ec37f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/interim/AmbisonicSoundLibrary/nature/W...</td>\n",
       "      <td>nature_AmbisonicSoundLibrary/nature</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/interim/AmbisonicSoundLibrary/nature/R...</td>\n",
       "      <td>nature_AmbisonicSoundLibrary/nature</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/interim/AmbisonicSoundLibrary/nature/A...</td>\n",
       "      <td>nature_AmbisonicSoundLibrary/nature</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/interim/AmbisonicSoundLibrary/nature/W...</td>\n",
       "      <td>nature_AmbisonicSoundLibrary/nature</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/interim/AmbisonicSoundLibrary/nature/L...</td>\n",
       "      <td>nature_AmbisonicSoundLibrary/nature</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>../data/interim/S2L_LULC/urban_26_100/s2lam111...</td>\n",
       "      <td>city_S2L_LULC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>../data/interim/S2L_LULC/urban_26_100/s2lam006...</td>\n",
       "      <td>city_S2L_LULC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>../data/interim/S2L_LULC/urban_26_100/s2lam083...</td>\n",
       "      <td>city_S2L_LULC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>../data/interim/S2L_LULC/urban_26_100/s2lam052...</td>\n",
       "      <td>city_S2L_LULC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>../data/interim/S2L_LULC/urban_26_100/s2lam098...</td>\n",
       "      <td>city_S2L_LULC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1924 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   file  \\\n",
       "0     ../data/interim/AmbisonicSoundLibrary/nature/W...   \n",
       "1     ../data/interim/AmbisonicSoundLibrary/nature/R...   \n",
       "2     ../data/interim/AmbisonicSoundLibrary/nature/A...   \n",
       "3     ../data/interim/AmbisonicSoundLibrary/nature/W...   \n",
       "4     ../data/interim/AmbisonicSoundLibrary/nature/L...   \n",
       "...                                                 ...   \n",
       "1919  ../data/interim/S2L_LULC/urban_26_100/s2lam111...   \n",
       "1920  ../data/interim/S2L_LULC/urban_26_100/s2lam006...   \n",
       "1921  ../data/interim/S2L_LULC/urban_26_100/s2lam083...   \n",
       "1922  ../data/interim/S2L_LULC/urban_26_100/s2lam052...   \n",
       "1923  ../data/interim/S2L_LULC/urban_26_100/s2lam098...   \n",
       "\n",
       "                                   source  category  \n",
       "0     nature_AmbisonicSoundLibrary/nature         0  \n",
       "1     nature_AmbisonicSoundLibrary/nature         0  \n",
       "2     nature_AmbisonicSoundLibrary/nature         0  \n",
       "3     nature_AmbisonicSoundLibrary/nature         0  \n",
       "4     nature_AmbisonicSoundLibrary/nature         0  \n",
       "...                                   ...       ...  \n",
       "1919                        city_S2L_LULC         1  \n",
       "1920                        city_S2L_LULC         1  \n",
       "1921                        city_S2L_LULC         1  \n",
       "1922                        city_S2L_LULC         1  \n",
       "1923                        city_S2L_LULC         1  \n",
       "\n",
       "[1924 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nature_df = pd.DataFrame({'file': nature_file_list, 'source': nature_source_list, 'category': 0})\n",
    "city_df = pd.DataFrame({'file': city_file_list, 'source': city_source_list, 'category': 1})\n",
    "df_all = pd.concat([nature_df, city_df], ignore_index=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f6baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # randomly sampled 80% as training, 10% as testing, and 10% and validation\n",
    "# test_df = df_all.groupby('source', group_keys=False).apply(lambda x: x.sample(frac=0.2, random_state=23))\n",
    "# val_df = test_df.groupby('source', group_keys=False).apply(lambda x: x.sample(frac=0.5, random_state=23))\n",
    "# # drop the ones got splitted out\n",
    "# train_df = df_all.drop(index = test_df.index)\n",
    "# test_df = test_df.drop(index = val_df.index)\n",
    "\n",
    "# test_df.reset_index(inplace=True, drop=True)\n",
    "# train_df.reset_index(inplace=True, drop=True)\n",
    "# val_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0078db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Split the data into folds using StratifiedKFold\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=23)\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['source'])):\n",
    "#     # Assign the fold number to each row in the DataFrame\n",
    "#     train_df.loc[val_idx, 'fold'] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b5c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Split the data into folds using StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=23)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df_all, df_all['source'])):\n",
    "    # Assign the fold number to each row in the DataFrame\n",
    "    df_all.loc[val_idx, 'fold'] = fold\n",
    "    \n",
    "df_all['fold'] = df_all['fold'].astype('int')\n",
    "df_all = df_all.sample(frac=1, random_state=23).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb0958c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/interim/S2L_LULC/urban_0_25/s2llg003_1...</td>\n",
       "      <td>nature_S2L_LULC/urban_0_25</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/interim/GoogleAudioSet/Outside, urban ...</td>\n",
       "      <td>city_GoogleAudioSet</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/interim/SONYC/audio-12/34_018803.pkl</td>\n",
       "      <td>city_SONYC</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/interim/GoogleAudioSet/Outside, urban ...</td>\n",
       "      <td>city_GoogleAudioSet</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/interim/GoogleAudioSet/Outside, urban ...</td>\n",
       "      <td>city_GoogleAudioSet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>../data/interim/SONYC/audio-4/22_004702.pkl</td>\n",
       "      <td>city_SONYC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>../data/interim/S2L_LULC/urban_0_25/s2lam042_1...</td>\n",
       "      <td>nature_S2L_LULC/urban_0_25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>../data/interim/GoogleAudioSet/Outside, urban ...</td>\n",
       "      <td>city_GoogleAudioSet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>../data/interim/S2L_LULC/urban_0_25/s2llg001_1...</td>\n",
       "      <td>nature_S2L_LULC/urban_0_25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>../data/interim/S2L_LULC/non_urban/s2llg004_17...</td>\n",
       "      <td>nature_S2L_LULC/non_urban</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1924 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   file  \\\n",
       "0     ../data/interim/S2L_LULC/urban_0_25/s2llg003_1...   \n",
       "1     ../data/interim/GoogleAudioSet/Outside, urban ...   \n",
       "2          ../data/interim/SONYC/audio-12/34_018803.pkl   \n",
       "3     ../data/interim/GoogleAudioSet/Outside, urban ...   \n",
       "4     ../data/interim/GoogleAudioSet/Outside, urban ...   \n",
       "...                                                 ...   \n",
       "1919        ../data/interim/SONYC/audio-4/22_004702.pkl   \n",
       "1920  ../data/interim/S2L_LULC/urban_0_25/s2lam042_1...   \n",
       "1921  ../data/interim/GoogleAudioSet/Outside, urban ...   \n",
       "1922  ../data/interim/S2L_LULC/urban_0_25/s2llg001_1...   \n",
       "1923  ../data/interim/S2L_LULC/non_urban/s2llg004_17...   \n",
       "\n",
       "                          source  category  fold  \n",
       "0     nature_S2L_LULC/urban_0_25         0     9  \n",
       "1            city_GoogleAudioSet         1     8  \n",
       "2                     city_SONYC         1     7  \n",
       "3            city_GoogleAudioSet         1     4  \n",
       "4            city_GoogleAudioSet         1     0  \n",
       "...                          ...       ...   ...  \n",
       "1919                  city_SONYC         1     1  \n",
       "1920  nature_S2L_LULC/urban_0_25         0     2  \n",
       "1921         city_GoogleAudioSet         1     1  \n",
       "1922  nature_S2L_LULC/urban_0_25         0     0  \n",
       "1923   nature_S2L_LULC/non_urban         0     0  \n",
       "\n",
       "[1924 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66afc0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = df_all['file']\n",
    "targets = df_all['category']\n",
    "folds = df_all['fold']\n",
    "\n",
    "main_ds = tf.data.Dataset.from_tensor_slices((filenames, targets, folds))\n",
    "main_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a936059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_pkl(filename):\n",
    "    import pickle\n",
    "    # open a file, where you stored the pickled data\n",
    "    file = open(filename, 'rb')\n",
    "\n",
    "    # dump information to that file\n",
    "    output = pickle.load(file)\n",
    "    wav = output['y']\n",
    "\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51d1b910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shorter length: 159999\n",
      "shorter length: 159880\n",
      "shorter length: 146099\n",
      "shorter length: 159880\n",
      "shorter length: 159880\n",
      "shorter length: 151683\n",
      "shorter length: 159880\n",
      "shorter length: 153357\n",
      "shorter length: 153242\n",
      "shorter length: 157848\n",
      "shorter length: 159992\n",
      "shorter length: 151461\n",
      "shorter length: 148006\n",
      "shorter length: 159997\n",
      "shorter length: 156480\n",
      "shorter length: 159993\n"
     ]
    }
   ],
   "source": [
    "wav_list = []\n",
    "for index, row in df_all.iterrows():\n",
    "    if len(load_wav_pkl(row['file'])) == 160000:\n",
    "        wav_list.append(load_wav_pkl(row['file']))\n",
    "    if len(load_wav_pkl(row['file'])) != 160000: # if the waveform is shorter (for unknown reason)\n",
    "        temp_wav = load_wav_pkl(row['file'])\n",
    "        print('shorter length: '+str(len(temp_wav)))\n",
    "        wav_list.append(np.pad(temp_wav, (0,160000-len(temp_wav)),'mean')) # zero-padding at the end to 160000\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53798c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(160000,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_ds = tf.data.Dataset.from_tensor_slices((np.stack(wav_list, axis = 0), df_all['category'], df_all['fold']))\n",
    "main_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a63c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(1024,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applies the embedding extraction model to a wav data\n",
    "def extract_embedding(wav_data, label, fold):\n",
    "    # run YAMNet to extract embedding from the wav data\n",
    "    scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
    "    num_embeddings = tf.shape(embeddings)[0]\n",
    "    return (embeddings,\n",
    "            tf.repeat(label, num_embeddings),\n",
    "            tf.repeat(fold, num_embeddings))\n",
    "\n",
    "# extract embedding\n",
    "main_ds = main_ds.map(extract_embedding).unbatch()\n",
    "main_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f4b192b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/andrewchang/opt/anaconda3/envs/AcousticEnv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/andrewchang/opt/anaconda3/envs/AcousticEnv/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "cached_ds = main_ds.cache()\n",
    "train_ds = cached_ds.filter(lambda embedding, label, fold: fold < 8)\n",
    "val_ds = cached_ds.filter(lambda embedding, label, fold: fold == 8)\n",
    "test_ds = cached_ds.filter(lambda embedding, label, fold: fold == 9)\n",
    "\n",
    "# remove the folds column now that it's not needed anymore\n",
    "remove_fold_column = lambda embedding, label, fold: (embedding, label)\n",
    "\n",
    "train_ds = train_ds.map(remove_fold_column)\n",
    "val_ds = val_ds.map(remove_fold_column)\n",
    "test_ds = test_ds.map(remove_fold_column)\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe243be",
   "metadata": {},
   "source": [
    "# Customize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efd43949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 525,826\n",
      "Trainable params: 525,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_classes = ['city', 'nature']\n",
    "my_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1024), dtype=tf.float32,\n",
    "                          name='input_embedding'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(my_classes))\n",
    "], name='my_model')\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f392d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                            patience=3,\n",
    "                                            restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbc4f668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "963/963 [==============================] - 134s 134ms/step - loss: 0.4224 - accuracy: 0.8106 - val_loss: 0.4727 - val_accuracy: 0.7995\n",
      "Epoch 2/20\n",
      "963/963 [==============================] - 6s 6ms/step - loss: 0.3689 - accuracy: 0.8395 - val_loss: 0.4839 - val_accuracy: 0.8031\n",
      "Epoch 3/20\n",
      "963/963 [==============================] - 6s 7ms/step - loss: 0.3337 - accuracy: 0.8578 - val_loss: 0.5007 - val_accuracy: 0.7961\n",
      "Epoch 4/20\n",
      "963/963 [==============================] - 8s 8ms/step - loss: 0.2997 - accuracy: 0.8706 - val_loss: 0.5255 - val_accuracy: 0.7958\n",
      "Epoch 5/20\n",
      "963/963 [==============================] - 9s 9ms/step - loss: 0.2754 - accuracy: 0.8847 - val_loss: 0.5299 - val_accuracy: 0.7945\n",
      "Epoch 6/20\n",
      "963/963 [==============================] - 8s 8ms/step - loss: 0.2766 - accuracy: 0.8916 - val_loss: 0.5533 - val_accuracy: 0.7930\n",
      "Epoch 7/20\n",
      "963/963 [==============================] - 7s 8ms/step - loss: 0.2377 - accuracy: 0.9024 - val_loss: 0.6086 - val_accuracy: 0.7911\n",
      "Epoch 8/20\n",
      "963/963 [==============================] - 8s 8ms/step - loss: 0.2236 - accuracy: 0.9097 - val_loss: 0.6427 - val_accuracy: 0.7977\n",
      "Epoch 9/20\n",
      "963/963 [==============================] - 9s 9ms/step - loss: 0.2121 - accuracy: 0.9186 - val_loss: 0.6528 - val_accuracy: 0.7943\n",
      "Epoch 10/20\n",
      "963/963 [==============================] - 10s 10ms/step - loss: 0.1897 - accuracy: 0.9222 - val_loss: 0.6849 - val_accuracy: 0.7859\n",
      "Epoch 11/20\n",
      "963/963 [==============================] - 10s 11ms/step - loss: 0.1798 - accuracy: 0.9298 - val_loss: 0.7051 - val_accuracy: 0.7935\n",
      "Epoch 12/20\n",
      "963/963 [==============================] - 11s 11ms/step - loss: 0.1639 - accuracy: 0.9347 - val_loss: 0.7137 - val_accuracy: 0.7940\n",
      "Epoch 13/20\n",
      "963/963 [==============================] - 11s 12ms/step - loss: 0.1494 - accuracy: 0.9388 - val_loss: 0.7468 - val_accuracy: 0.7927\n",
      "Epoch 14/20\n",
      "963/963 [==============================] - 11s 11ms/step - loss: 0.1477 - accuracy: 0.9434 - val_loss: 0.7891 - val_accuracy: 0.7820\n",
      "Epoch 15/20\n",
      "963/963 [==============================] - 11s 12ms/step - loss: 0.1335 - accuracy: 0.9470 - val_loss: 0.8365 - val_accuracy: 0.7820\n",
      "Epoch 16/20\n",
      "963/963 [==============================] - 10s 11ms/step - loss: 0.1237 - accuracy: 0.9514 - val_loss: 0.8597 - val_accuracy: 0.7859\n",
      "Epoch 17/20\n",
      "963/963 [==============================] - 10s 10ms/step - loss: 0.1162 - accuracy: 0.9547 - val_loss: 0.8963 - val_accuracy: 0.7904\n",
      "Epoch 18/20\n",
      "963/963 [==============================] - 9s 9ms/step - loss: 0.1122 - accuracy: 0.9569 - val_loss: 0.9130 - val_accuracy: 0.7794\n",
      "Epoch 19/20\n",
      "963/963 [==============================] - 9s 9ms/step - loss: 0.1051 - accuracy: 0.9596 - val_loss: 0.9302 - val_accuracy: 0.7797\n",
      "Epoch 20/20\n",
      "963/963 [==============================] - 12s 12ms/step - loss: 0.0965 - accuracy: 0.9639 - val_loss: 1.0306 - val_accuracy: 0.7799\n"
     ]
    }
   ],
   "source": [
    "history = my_model.fit(train_ds,\n",
    "                       epochs=20,\n",
    "                       validation_data=val_ds,\n",
    "                       callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a131c811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 2s 6ms/step - loss: 1.2178 - accuracy: 0.7622\n",
      "Loss:  1.2177757024765015\n",
      "Accuracy:  0.7622395753860474\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = my_model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9838c0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
