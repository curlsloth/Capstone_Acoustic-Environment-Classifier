{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f194994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 00:25:22.125133: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-03 00:25:27.350246: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from IPython import display\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle) # if there's an \"SavedModel file does not exist at:\", delete that folder and rerun it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24109e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "      <th>weight</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_nature</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13662</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13663</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13664</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13665</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13666</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13667 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    file         source  \\\n",
       "0      ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "1      ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "2      ../data/interim/GoogleAudioSet_unbalanced_list...  Google_nature   \n",
       "3      ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "4      ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "...                                                  ...            ...   \n",
       "13662  ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "13663  ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "13664  ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "13665  ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "13666  ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "\n",
       "       category  weight  fold  \n",
       "0             1       1     0  \n",
       "1             1       1     8  \n",
       "2             0       1     5  \n",
       "3             1       1     1  \n",
       "4             1       1     1  \n",
       "...         ...     ...   ...  \n",
       "13662         1       1     5  \n",
       "13663         1       1     3  \n",
       "13664         1       1     8  \n",
       "13665         1       1     8  \n",
       "13666         1       1     0  \n",
       "\n",
       "[13667 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv('../train_val_test_split/train_val_test_GoogleAudioSet.csv', index_col=0)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad3fc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "Google_city      6687\n",
       "Google_nature    6980\n",
       "Name: weight, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the weight\n",
    "df_all.groupby(['source'])['weight'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc42333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_yamnet_embedding(filename):\n",
    "    import pickle\n",
    "    \n",
    "    file = open(filename, 'rb')\n",
    "    output = pickle.load(file)\n",
    "#     output = pd.read_pickle(file)\n",
    "    wav_raw = output['y']\n",
    "    wav_bg = output['bg_y']\n",
    "    wav_fg = output['fg_y']\n",
    "    file.close()\n",
    "\n",
    "# # no need to run padding as the time dimension will be collapsed after transforming to embeddings anyway    \n",
    "#     if len(wav_raw) < 160000:\n",
    "#         wav_raw = np.pad(wav_raw, (0,160000-len(wav_raw)),'mean')\n",
    "\n",
    "#     if len(wav_bg) < 160000:\n",
    "#         wav_bg = np.pad(wav_bg, (0,160000-len(wav_bg)),'mean')\n",
    "\n",
    "#     if len(wav_fg) < 160000:\n",
    "#         wav_fg = np.pad(wav_fg, (0,160000-len(wav_fg)),'mean')\n",
    "\n",
    "    # Extract YAMNet embeddings for each frame\n",
    "    scores, embedding_tensor_raw, spectrogram = yamnet_model(wav_raw)\n",
    "    embedding_tensor_raw = tf.reduce_mean(embedding_tensor_raw, axis=0).numpy()\n",
    "\n",
    "    scores, embedding_tensor_bg, spectrogram = yamnet_model(wav_bg)\n",
    "    embedding_tensor_bg = tf.reduce_mean(embedding_tensor_bg, axis=0).numpy()\n",
    "\n",
    "    scores, embedding_tensor_fg, spectrogram = yamnet_model(wav_fg)\n",
    "    embedding_tensor_fg = tf.reduce_mean(embedding_tensor_fg, axis=0).numpy()\n",
    "        \n",
    "    \n",
    "    return embedding_tensor_raw, embedding_tensor_bg, embedding_tensor_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe3107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds: 2662.80260515213\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "embeddings_raw_list = []\n",
    "embeddings_bg_list = []\n",
    "embeddings_fg_list = []\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for index, row in df_all.iterrows():\n",
    "    embedding_tensor_raw, embedding_tensor_bg, embedding_tensor_fg = extract_yamnet_embedding(row['file'])\n",
    "    \n",
    "    embeddings_raw_list.append(embedding_tensor_raw)\n",
    "    embeddings_bg_list.append(embedding_tensor_bg)\n",
    "    embeddings_fg_list.append(embedding_tensor_fg)\n",
    "    \n",
    "embeddings_raw_matrix = np.stack(embeddings_raw_list, axis=0)\n",
    "embeddings_bg_matrix = np.stack(embeddings_bg_list, axis=0)\n",
    "embeddings_fg_matrix = np.stack(embeddings_fg_list, axis=0)\n",
    "    \n",
    "print('seconds: '+str(time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1eb5a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_matrix = np.concatenate((embeddings_raw_matrix, embeddings_bg_matrix, embeddings_fg_matrix), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f646ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = df_all['fold']<8\n",
    "valid_index = df_all['fold']==8\n",
    "test_index = df_all['fold']==9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd27d80",
   "metadata": {},
   "source": [
    "# Raw signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = embeddings_raw_matrix[train_index,:]\n",
    "y_train = df_all.loc[train_index,'category']\n",
    "X_valid = embeddings_raw_matrix[valid_index,:]\n",
    "y_valid = df_all.loc[valid_index,'category']\n",
    "\n",
    "transformer = Pipeline(steps=[\n",
    "       ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean'))\n",
    "      ,('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "transformer.fit(X_train)\n",
    "X_train = transformer.transform(X_train)\n",
    "X_valid = transformer.transform(X_valid)\n",
    "\n",
    "\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_valid, y_train, y_valid)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beef6f41",
   "metadata": {},
   "source": [
    "# Background signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270015db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = embeddings_bg_matrix[train_index,:]\n",
    "y_train = df_all.loc[train_index,'category']\n",
    "X_valid = embeddings_bg_matrix[valid_index,:]\n",
    "y_valid = df_all.loc[valid_index,'category']\n",
    "\n",
    "transformer = Pipeline(steps=[\n",
    "       ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean'))\n",
    "      ,('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "transformer.fit(X_train)\n",
    "X_train = transformer.transform(X_train)\n",
    "X_valid = transformer.transform(X_valid)\n",
    "\n",
    "\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_valid, y_train, y_valid)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3827870",
   "metadata": {},
   "source": [
    "# Foreground signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = embeddings_fg_matrix[train_index,:]\n",
    "y_train = df_all.loc[train_index,'category']\n",
    "X_valid = embeddings_fg_matrix[valid_index,:]\n",
    "y_valid = df_all.loc[valid_index,'category']\n",
    "\n",
    "transformer = Pipeline(steps=[\n",
    "       ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean'))\n",
    "      ,('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "transformer.fit(X_train)\n",
    "X_train = transformer.transform(X_train)\n",
    "X_valid = transformer.transform(X_valid)\n",
    "\n",
    "\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_valid, y_train, y_valid)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c72185",
   "metadata": {},
   "source": [
    "# All signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11a7d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [28:16<00:00, 58.49s/it]\n"
     ]
    }
   ],
   "source": [
    "X_train = embeddings_matrix[train_index,:]\n",
    "y_train = df_all.loc[train_index,'category']\n",
    "X_valid = embeddings_matrix[valid_index,:]\n",
    "y_valid = df_all.loc[valid_index,'category']\n",
    "\n",
    "transformer = Pipeline(steps=[\n",
    "       ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean'))\n",
    "      ,('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "transformer.fit(X_train)\n",
    "X_train = transformer.transform(X_train)\n",
    "X_valid = transformer.transform(X_valid)\n",
    "\n",
    "\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_valid, y_train, y_valid)\n",
    "models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54ab453e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>209.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>350.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>11.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>14.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>34.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>22.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>91.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>127.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>12.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>19.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>74.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>239.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>378.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>29.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>33.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>13.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "SVC                                0.70               0.70     0.70      0.70   \n",
       "NuSVC                              0.70               0.70     0.70      0.70   \n",
       "ExtraTreesClassifier               0.70               0.70     0.70      0.70   \n",
       "LGBMClassifier                     0.69               0.69     0.69      0.69   \n",
       "RandomForestClassifier             0.69               0.69     0.69      0.69   \n",
       "RidgeClassifierCV                  0.69               0.69     0.69      0.69   \n",
       "LogisticRegression                 0.68               0.68     0.68      0.68   \n",
       "XGBClassifier                      0.68               0.68     0.68      0.68   \n",
       "AdaBoostClassifier                 0.68               0.68     0.68      0.68   \n",
       "RidgeClassifier                    0.67               0.67     0.67      0.67   \n",
       "LinearDiscriminantAnalysis         0.67               0.67     0.67      0.67   \n",
       "LinearSVC                          0.66               0.66     0.66      0.66   \n",
       "NearestCentroid                    0.66               0.66     0.66      0.66   \n",
       "BaggingClassifier                  0.66               0.66     0.66      0.66   \n",
       "PassiveAggressiveClassifier        0.66               0.66     0.66      0.66   \n",
       "KNeighborsClassifier               0.65               0.65     0.65      0.65   \n",
       "SGDClassifier                      0.65               0.65     0.65      0.65   \n",
       "BernoulliNB                        0.65               0.65     0.65      0.65   \n",
       "CalibratedClassifierCV             0.64               0.64     0.64      0.64   \n",
       "DecisionTreeClassifier             0.61               0.61     0.61      0.61   \n",
       "Perceptron                         0.61               0.61     0.61      0.60   \n",
       "ExtraTreeClassifier                0.60               0.60     0.60      0.60   \n",
       "GaussianNB                         0.61               0.60     0.60      0.56   \n",
       "QuadraticDiscriminantAnalysis      0.49               0.50     0.50      0.34   \n",
       "DummyClassifier                    0.51               0.50     0.50      0.35   \n",
       "LabelPropagation                   0.51               0.50     0.50      0.34   \n",
       "LabelSpreading                     0.51               0.50     0.50      0.34   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "SVC                                209.60  \n",
       "NuSVC                              350.83  \n",
       "ExtraTreesClassifier                11.98  \n",
       "LGBMClassifier                      14.68  \n",
       "RandomForestClassifier              34.83  \n",
       "RidgeClassifierCV                   22.95  \n",
       "LogisticRegression                   2.72  \n",
       "XGBClassifier                       91.35  \n",
       "AdaBoostClassifier                 127.93  \n",
       "RidgeClassifier                     12.61  \n",
       "LinearDiscriminantAnalysis          19.73  \n",
       "LinearSVC                           74.38  \n",
       "NearestCentroid                      1.00  \n",
       "BaggingClassifier                  239.98  \n",
       "PassiveAggressiveClassifier          2.94  \n",
       "KNeighborsClassifier                 1.86  \n",
       "SGDClassifier                        6.01  \n",
       "BernoulliNB                          2.00  \n",
       "CalibratedClassifierCV             378.99  \n",
       "DecisionTreeClassifier              29.98  \n",
       "Perceptron                           1.91  \n",
       "ExtraTreeClassifier                  1.02  \n",
       "GaussianNB                           1.16  \n",
       "QuadraticDiscriminantAnalysis       33.11  \n",
       "DummyClassifier                      0.93  \n",
       "LabelPropagation                     7.66  \n",
       "LabelSpreading                      13.10  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a057b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77293cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf493fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff04409b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# # Define a function to extract YAMNet embeddings for a single audio file\n",
    "# def extract_yamnet_embedding(audio_path):\n",
    "#     # Load the audio file\n",
    "#     audio, sample_rate = tf.audio.decode_wav(tf.io.read_file(audio_path))\n",
    "    \n",
    "#     # Extract YAMNet embeddings for each frame\n",
    "#     embedding_tensor = yamnet_model(audio)\n",
    "#     embeddings = tf.reduce_mean(embedding_tensor, axis=0)\n",
    "    \n",
    "#     return embeddings\n",
    "\n",
    "# # Define a function to parse a single metadata file\n",
    "# def parse_metadata(metadata_path):\n",
    "#     # Implement your metadata parsing code here\n",
    "#     metadata = ...\n",
    "    \n",
    "#     return metadata\n",
    "\n",
    "# # Define a function to combine YAMNet embeddings and metadata for a single audio file\n",
    "# def combine_features(audio_path, metadata_path):\n",
    "#     # Extract YAMNet embeddings\n",
    "#     yamnet_embedding = extract_yamnet_embedding(audio_path)\n",
    "    \n",
    "#     # Parse metadata\n",
    "#     metadata = parse_metadata(metadata_path)\n",
    "    \n",
    "#     # Concatenate the YAMNet embedding and metadata into a single feature vector\n",
    "#     feature_vector = tf.concat([yamnet_embedding, metadata], axis=-1)\n",
    "    \n",
    "#     return feature_vector\n",
    "\n",
    "# # Define a function to load and preprocess a single data sample\n",
    "# def load_and_preprocess_data(audio_path, metadata_path):\n",
    "#     # Combine YAMNet embeddings and metadata\n",
    "#     feature_vector = combine_features(audio_path, metadata_path)\n",
    "    \n",
    "#     # Implement your data preprocessing code here\n",
    "#     preprocessed_data = ...\n",
    "    \n",
    "#     return preprocessed_data\n",
    "\n",
    "# # Load a list of audio and metadata file paths\n",
    "# audio_paths = [\"path/to/audio1.wav\", \"path/to/audio2.wav\", ...]\n",
    "# metadata_paths = [\"path/to/metadata1.csv\", \"path/to/metadata2.csv\", ...]\n",
    "\n",
    "# # Create a TensorFlow dataset using the audio and metadata file paths\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((audio_paths, metadata_paths))\n",
    "\n",
    "# # Use the map function to apply the load_and_preprocess_data function to each sample in the dataset\n",
    "# dataset = dataset.map(load_and_preprocess_data)\n",
    "\n",
    "# # Implement your training code here using the preprocessed dataset\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
