{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77891e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 23:13:51.794808: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: /var/folders/fw/slnm06yn15lgwlcg_7jpt3t00000gn/T/tfhub_modules/9616fd04ec2360621642ef9455b84f4b668e219e/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m---> 20\u001b[0m yamnet_model \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://tfhub.dev/google/yamnet/1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# if there's an \"SavedModel file does not exist at:\", delete that folder and rerun it\u001b[39;00m\n\u001b[1;32m     21\u001b[0m vggish_model \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/google/vggish/1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AcousticEnv/lib/python3.8/site-packages/tensorflow_hub/module_v2.py:106\u001b[0m, in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m    103\u001b[0m   obj \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mload_v2(\n\u001b[1;32m    104\u001b[0m       module_path, tags\u001b[38;5;241m=\u001b[39mtags, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m   obj \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m obj\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m is_hub_module_v1  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AcousticEnv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:828\u001b[0m, in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[1;32m    827\u001b[0m   export_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(export_dir)\n\u001b[0;32m--> 828\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AcousticEnv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:933\u001b[0m, in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, \u001b[38;5;28mset\u001b[39m):\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;66;03m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[1;32m    931\u001b[0m   tags \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(tags)\n\u001b[1;32m    932\u001b[0m saved_model_proto, debug_info \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 933\u001b[0m     \u001b[43mloader_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_saved_model_with_debug_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    936\u001b[0m     saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_graph_def\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    937\u001b[0m   metrics\u001b[38;5;241m.\u001b[39mIncrementReadApi(_LOAD_V2_LABEL)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AcousticEnv/lib/python3.8/site-packages/tensorflow/python/saved_model/loader_impl.py:57\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m   saved_model \u001b[38;5;241m=\u001b[39m \u001b[43mparse_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m   debug_info_path \u001b[38;5;241m=\u001b[39m file_io\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     60\u001b[0m       saved_model_utils\u001b[38;5;241m.\u001b[39mget_debug_dir(export_dir),\n\u001b[1;32m     61\u001b[0m       constants\u001b[38;5;241m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[1;32m     62\u001b[0m   debug_info \u001b[38;5;241m=\u001b[39m graph_debug_info_pb2\u001b[38;5;241m.\u001b[39mGraphDebugInfo()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/AcousticEnv/lib/python3.8/site-packages/tensorflow/python/saved_model/loader_impl.py:115\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot parse file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_pbtxt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    116\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel file does not exist at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexport_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /var/folders/fw/slnm06yn15lgwlcg_7jpt3t00000gn/T/tfhub_modules/9616fd04ec2360621642ef9455b84f4b668e219e/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from IPython import display\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1') # if there's an \"SavedModel file does not exist at:\", delete that folder and rerun it\n",
    "vggish_model = hub.load('https://tfhub.dev/google/vggish/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('../train_val_test_split/train_val_test_GoogleAudioSet.csv', index_col=0)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a5f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(filename):\n",
    "    import pickle\n",
    "    \n",
    "    file = open(filename, 'rb')\n",
    "    output = pickle.load(file)\n",
    "#     output = pd.read_pickle(file)\n",
    "    wav_raw = output['y']\n",
    "    wav_bg = output['bg_y']\n",
    "    wav_fg = output['fg_y']\n",
    "    \n",
    "    df_indices_raw = output['df_indices']\n",
    "    df_indices_fg = output['df_indices_fg']\n",
    "    df_indices_bg = output['df_indices_bg']\n",
    "    \n",
    "    wt = output['wt']\n",
    "    mps_raw = output['mps']\n",
    "    mps_fg = output['mps_fg']\n",
    "    mps_bg = output['mps_bg']\n",
    "    mps_raw = mps_raw[:,wt<=100].reshape(-1) # exclude the temporal modulation frequency >100 Hz\n",
    "    mps_fg = mps_fg[:,wt<=100].reshape(-1)\n",
    "    mps_bg = mps_bg[:,wt<=100].reshape(-1)\n",
    "    \n",
    "    file.close()\n",
    "\n",
    "    # Extract YAMNet embeddings for each frame\n",
    "    scores, embedding_tensor_raw, spectrogram = yamnet_model(wav_raw)\n",
    "    embedding_tensor_raw = tf.reduce_mean(embedding_tensor_raw, axis=0).numpy()\n",
    "\n",
    "    scores, embedding_tensor_bg, spectrogram = yamnet_model(wav_bg)\n",
    "    embedding_tensor_bg = tf.reduce_mean(embedding_tensor_bg, axis=0).numpy()\n",
    "\n",
    "    scores, embedding_tensor_fg, spectrogram = yamnet_model(wav_fg)\n",
    "    embedding_tensor_fg = tf.reduce_mean(embedding_tensor_fg, axis=0).numpy()\n",
    "    \n",
    "    \n",
    "    # Extract VGGish embeddings for each frame\n",
    "    vggish_embedding_raw = tf.reduce_mean(vggish_model(wav_raw), axis=0).numpy()\n",
    "    vggish_embedding_bg = tf.reduce_mean(vggish_model(wav_bg), axis=0).numpy()\n",
    "    vggish_embedding_fg = tf.reduce_mean(vggish_model(wav_fg), axis=0).numpy()\n",
    "   \n",
    "    return embedding_tensor_raw, embedding_tensor_bg, embedding_tensor_fg, mps_raw, mps_bg, mps_fg, df_indices_raw, df_indices_bg, df_indices_fg, vggish_embedding_raw, vggish_embedding_bg, vggish_embedding_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b907e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_raw_list = []\n",
    "embedding_bg_list = []\n",
    "embedding_fg_list = []\n",
    "mps_raw_list = []\n",
    "mps_bg_list = []\n",
    "mps_fg_list = []\n",
    "indices_raw_list = []\n",
    "indices_bg_list = []\n",
    "indices_fg_list = []\n",
    "vgg_raw_list = []\n",
    "vgg_bg_list = []\n",
    "vgg_fg_list = []\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for index, row in df_all.iterrows():\n",
    "    embedding_tensor_raw, embedding_tensor_bg, embedding_tensor_fg, mps_raw, mps_bg, mps_fg, df_indices_raw, df_indices_bg, df_indices_fg, vggish_embedding_raw, vggish_embedding_bg, vggish_embedding_fg = data_preprocessing(row['file'])\n",
    "    \n",
    "    embedding_raw_list.append(embedding_tensor_raw)\n",
    "    embedding_bg_list.append(embedding_tensor_bg)\n",
    "    embedding_fg_list.append(embedding_tensor_fg)\n",
    "    mps_raw_list.append(mps_raw)\n",
    "    mps_bg_list.append(mps_bg)\n",
    "    mps_fg_list.append(mps_fg)\n",
    "    indices_raw_list.append(df_indices_raw)\n",
    "    indices_bg_list.append(df_indices_bg)\n",
    "    indices_fg_list.append(df_indices_fg)\n",
    "    vgg_raw_list.append(vggish_embedding_raw)\n",
    "    vgg_bg_list.append(vggish_embedding_bg)\n",
    "    vgg_fg_list.append(vggish_embedding_fg)\n",
    "\n",
    "    \n",
    "print('seconds: '+str(time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bda728",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_raw_matrix = np.stack(embedding_raw_list, axis=0)\n",
    "embedding_bg_matrix = np.stack(embedding_bg_list, axis=0)\n",
    "embedding_fg_matrix = np.stack(embedding_fg_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08770546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indices_raw = pd.concat(indices_raw_list, ignore_index=True)\n",
    "df_indices_bg = pd.concat(indices_bg_list, ignore_index=True)\n",
    "df_indices_fg = pd.concat(indices_fg_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_raw_matrix = np.stack(mps_raw_list)\n",
    "mps_bg_matrix = np.stack(mps_bg_list)\n",
    "mps_fg_matrix = np.stack(mps_fg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_raw_matrix = np.stack(vgg_raw_list, axis=0)\n",
    "vgg_bg_matrix = np.stack(vgg_bg_list, axis=0)\n",
    "vgg_fg_matrix = np.stack(vgg_fg_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b29161",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/processed/20230304/embedding_raw_matrix.npy', embedding_raw_matrix)\n",
    "np.save('../data/processed/20230304/embedding_bg_matrix.npy', embedding_bg_matrix)\n",
    "np.save('../data/processed/20230304/embedding_fg_matrix.npy', embedding_fg_matrix)\n",
    "\n",
    "np.save('../data/processed/20230304/vgg_raw_matrix.npy', vgg_raw_matrix)\n",
    "np.save('../data/processed/20230304/vgg_bg_matrix.npy', vgg_bg_matrix)\n",
    "np.save('../data/processed/20230304/vgg_fg_matrix.npy', vgg_fg_matrix)\n",
    "\n",
    "np.save('../data/processed/20230304/mps_raw_matrix.npy', mps_raw_matrix)\n",
    "np.save('../data/processed/20230304/mps_bg_matrix.npy', mps_bg_matrix)\n",
    "np.save('../data/processed/20230304/mps_fg_matrix.npy', mps_fg_matrix)\n",
    "\n",
    "df_indices_raw.to_csv('../data/processed/20230304/df_indices_raw.csv')\n",
    "df_indices_bg.to_csv('../data/processed/20230304/df_indices_bg.csv')\n",
    "df_indices_fg.to_csv('../data/processed/20230304/df_indices_fg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e561ca42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
